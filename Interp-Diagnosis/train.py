# -*- coding: utf-8 -*-
"""Projectcode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tU3EbOtWCHv5z-MSJs46KuTzPoGlrDnf
"""

torch_version_suffix = "+cu110"
import os
from pathlib import Path

import numpy as np
import pandas as pd
import torch
from PIL import Image
from torch import nn
from torch.optim import lr_scheduler
from torch.utils.data import Dataset, DataLoader
from torchvision.transforms import Resize

import clip
from clip.simple_tokenizer import SimpleTokenizer

device = "cuda" if torch.cuda.is_available() else "cpu"

# %matplotlib inline
# %config InlineBackend.figure_format = 'retina'

_tokenizer = SimpleTokenizer()

def tokenize(texts, context_length: int = 77) -> torch.LongTensor:
    if isinstance(texts, str):
        texts = [texts]

    sot_token = _tokenizer.encoder["<|startoftext|>"]
    eot_token = _tokenizer.encoder["<|endoftext|>"]
    all_tokens = [[sot_token] + _tokenizer.encode(text) + [eot_token] for text in texts]
    result = torch.zeros(len(all_tokens), context_length, dtype=torch.long)

    for i, tokens in enumerate(all_tokens):
        n = min(len(tokens), context_length)
        result[i, :n] = torch.tensor(tokens)[:n]
        if len(tokens) > context_length:
            result[i, -1] = tokens[-1]

    return result

class RollingMean():
    def __init__(self):
        self.n = 0
        self.mean = 0
        
    def update(self, value):
        self.mean = (self.mean * self.n + value) / (self.n+1)
        self.n += 1
        
    def result(self):
        return self.mean

class MyDataset(Dataset):
    def __init__(self, df, images_path, transform):
        # super().__init__()
        self.transform = transform
        self.df = df
        self.images_path = images_path
        #self.classes = ['no','pre-proliferative','proliferative']
        self.classes = ['the diabetic retinopathy label level is normal',
                        'the diabetic retinopathy label level is background diabetic retinopathy',
                        'the diabetic retinopathy label level is degrees of referable diabetic retinopathy']
        data = {}
        for k,v in df.groupby('level'):
            if len(v) < 1000:
                data[k] = v
            else:
                data[k] = v.iloc[:len(v),:]
        self.data = pd.concat([data[i] for i in range(3) if i in data],axis=0)

    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        img_name, text = self.df.iloc[idx,:].values
        image = self.transform(Image.open(os.path.join(self.images_path, img_name+'.jpeg')))
        return image, text


# class Metric():
#     def __init__(self, CLASSES):
#         self.CLASSES = CLASSES
#         self.top1recall = {}
#         self.top1precision = {}

#     def clear(self):
#         for i in range(len(self.CLASSES)):
#             self.top1recall[i] = []
#             self.top1precision[i] = []
#     def update(self, similarity, labels):
#         #similarity:Nx7 labels:N
#         for i, label in enumerate(labels):
#             tar = int(label)
#             pre = similarity[i].topk(1).indices
#             if pre == label:
#                 self.top1precision[int(pre)].append(1)
#                 self.top1recall[tar].append(1)
#             else:
#                 self.top1precision[int(pre)].append(0)
#                 self.top1recall[tar].append(0)   
#     def report(self):
#         table_header = ["class","Precision","Recall","F1"]
#         table_data = []
#         for i, cls in enumerate(self.CLASSES):
#             recall = np.mean(self.top1recall[i])
#             precision = np.mean(self.top1precision[i])
#             f1 = 2 * (precision * recall) / (precision + recall)
#             table_data.append((cls, str(precision)[:4], str(recall)[:4], str(f1)[:4]))

#         print(tabulate(table_data, headers=table_header, tablefmt='grid'))

def train(n_epochs, batch_size, learning_rate):
    # Load CLIP
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load('ViT-B/32', device)
    model.train()  

    # load train data
    train_images_path = Path('/Users/shuumichi/Desktop/CLIP-main/data/train/train0')

    df_train = pd.read_csv('/Users/shuumichi/Desktop/CLIP-main/data/train0.csv')

    dstrain = MyDataset(df_train, train_images_path, preprocess)
    # print(dstrain.data[:5])
    dltrain = DataLoader(dstrain, batch_size=batch_size, shuffle=False, num_workers=4, drop_last=False)
    texts = torch.cat([clip.tokenize(f"{c} retinopathy") for c in dstrain.classes]).to(device)

    # optim = torch.optim.AdamW(model.parameters(), lr=learning_rate, eps=1e-8, weight_decay=1e-2)
    classifier = nn.Sequential(nn.Linear(512, 64),
                            nn.ReLU(),
                            nn.Linear(64, 3),
                            nn.Sigmoid())

    classifier.train()
    optim = torch.optim.Adam(classifier.parameters(), lr=learning_rate, betas=(0.9,0.99))
    scheduler = lr_scheduler.StepLR(optim, step_size=20, gamma=0.3)

    #loss_img = nn.CrossEntropyLoss(weight=torch.FloatTensor([0.1,1.5,0.5])).to(device)
    loss_img = nn.CrossEntropyLoss(weight=torch.FloatTensor([0.5, 0.5, 0.5])).to(device)

    # finetune
    best_loss = np.inf
    for i in range(n_epochs):
        batch_loss = RollingMean()
        # cnt = 0
        # for images, labels in tqdm(dltrain):
        for images, labels in dltrain:

            if labels.size()[0] != batch_size:
                continue

            if labels==([0]) : texts =clip.tokenize (['the diabetic retinopathy label level is normal'])
            elif labels==([1]) : texts =clip.tokenize(['the diabetic retinopathy label level is background diabetic retinopathy'])
            else : texts = clip.tokenize(['the diabetic retinopathy label level is degrees of referable diabetic retinopathy'])

            optim.zero_grad()
            image_features = model.encode_image(images.to(device))
            texts = model.encode_text(texts)
            predictions = classifier(image_features)
            texts = classifier(texts)
            loss = loss_img(predictions, texts)
            
            loss.backward()
            optim.step()

            # Update metric
            batch_loss.update(loss.item())

            # if cnt % 100 == 0:
            #     print('epoch: {}, batch count: {}, loss: {}'.format(i, cnt, batch_loss.result()))
            # cnt += 1

        scheduler.step()
        loss_mean = batch_loss.result()
        print('epoch: {}, total loss: {}'.format(i, loss_mean))

        if loss_mean < best_loss:
            best_loss = loss_mean
            torch.save({
                    'epoch': i,
                    'model_state_dict': classifier.state_dict(),
                    'optimizer_state_dict': optim.state_dict(),
                    'loss': loss_mean,
                    }, f"classifier1.pt")
        #print(classifier.state_dict())

# model, preprocess = clip.load("ViT-B/32",device=device,jit=False) 
# checkpoint = torch.load("model.pt")
# model.load_state_dict(checkpoint['model_state_dict'])

def main():
    train(n_epochs=2, batch_size=1, learning_rate=5e-3)

if __name__=="__main__":
    main()
